

.. _sphx_glr_auto_examples_ex_anonymous_transformer.py:


===============================
Anonymous transformers in skoot
===============================

Sometimes you have a pre-processing stage that finds itself awkwardly
positioned in the middle of your pipeline and you're left with one of
two options:

  1. Write a full transformer class
  2. Break your pipeline up into pieces

Obviously, the preferable action is the first, however many times your
function doesn't actually fit any training set parameters, so the transformer
feels like overkill.

This tutorial will introduce you to making anonymous, lightweight transformers
on the fly that will fit into your modeling pipeline seamlessly.

.. raw:: html

   <br/>





.. rst-class:: sphx-glr-script-out

 Out::

    Absolute scaled values: 
         StandardScaler1  StandardScaler2  StandardScaler3  StandardScaler4
    73          0.354517         0.579258         0.557645         0.023324
    18          0.133071         1.670289         1.162597         1.176203
    118         2.304867         1.029168         1.819157         1.489413
    78          0.232620         0.354304         0.442962         0.423166
    76          1.207795         0.579258         0.614987         0.289886
    31          0.498762         0.770470         1.277280         1.042922
    64          0.254968         0.354304         0.073110         0.156605
    141         1.329692         0.095606         0.787011         1.489413
    68          0.476414         1.928987         0.442962         0.423166
    82          0.011174         0.804213         0.098914         0.023324
    110         0.842104         0.320560         0.787011         1.089570
    12          1.230143         0.129349         1.334622         1.442764
    36          0.376865         0.995425         1.391963         1.309484
    9           1.108246         0.095606         1.277280         1.442764
    19          0.864452         1.670289         1.277280         1.176203
    56          0.598311         0.545515         0.557645         0.556447
    104         0.842104         0.129349         1.188401         1.356132
    69          0.254968         1.254122         0.098914         0.109957
    55          0.133071         0.579258         0.442962         0.156605
    132         0.720208         0.579258         1.073718         1.356132
    29          1.352040         0.320560         1.219939         1.309484
    127         0.354517         0.129349         0.672328         0.823009
    26          0.986349         0.770470         1.219939         1.042922
    128         0.720208         0.579258         1.073718         1.222851
    131         2.548661         1.670289         1.532449         1.089570
    145         1.085898         0.129349         0.844352         1.489413
    108         1.085898         1.254122         1.188401         0.823009
    143         1.207795         0.320560         1.245742         1.489413
    45          1.230143         0.129349         1.334622         1.176203
    30          1.230143         0.095606         1.219939         1.309484




|


.. code-block:: python

    print(__doc__)

    # Author: Taylor Smith <taylor.smith@alkaline-ml.com>

    # #############################################################################
    # Introduce an interesting scenario
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import Pipeline
    from skoot.preprocessing import SelectiveStandardScaler
    from skoot.base import make_transformer
    from skoot.datasets import load_iris_df

    X = load_iris_df(tgt_name="target")
    y = X.pop('target')
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,
                                                        test_size=0.2)

    # Let's say we want to scale our features with the StandardScaler, but
    # for whatever reason we only want the ABSOLUTE value of the scaled values.
    # We *could* create a transformer or split our pipeline, but either case is
    # klunky and could interrupt our CV process in a grid search.
    #
    # So we'll instead define a simple commutative function that will be wrapped
    # in an "anonymous" transformer
    def make_abs(X):
        return X.abs()


    pipe = Pipeline([
        ("scale", SelectiveStandardScaler()),
        ("abs", make_transformer(make_abs))
    ])

    pipe.fit(X_train, y_train)
    print("Absolute scaled values: ")
    print(pipe.transform(X_test))

**Total running time of the script:** ( 0 minutes  0.017 seconds)



.. only :: html

 .. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: ex_anonymous_transformer.py <ex_anonymous_transformer.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: ex_anonymous_transformer.ipynb <ex_anonymous_transformer.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
